{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the WebDriver in Selenium as the browser automation framework for this webscraping project.\n",
    "from selenium import webdriver\n",
    "\n",
    "# Using service to start and stop local drivers, which in this case would be Geckodriver. \n",
    "from selenium.webdriver.firefox.service import Service as FIREFOXSERVICE\n",
    "\n",
    "# Using By to locate elements using their class names.\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# Using Beautiful Soup to parse the HTML of a webpage.\n",
    "import bs4\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "from PIL import Image, UnidentifiedImageError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function that is used to obtain all of the image URLs. Here, the WebDriver first verifies that an element of the webpage is an image using its class name (to avoid clicking on a related search box). The WebDriver then clicks on it and verifies that its URL is usable. The URL is then stored and this process is repeated until the desired number of image URLs is obtained. Once the function has finished this process, all of the stored image URLs are returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images(driver, thumbnails, max_images):\n",
    "\n",
    "    image_URLs = set() # Where all of the usable image URLs are stored.\n",
    "\n",
    "    for img in thumbnails[len(image_URLs): max_images]: # Loops through the images of the webpage to obtain and store the number of image URLs requested.\n",
    "        try: \n",
    "            img.click()\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        images = driver.find_elements(By.CLASS_NAME, \"iPVvYb\") # This class name is obtained from the actual image and not its thumbnail.\n",
    "        for image in images:\n",
    "            if image.get_attribute('src') in image_URLs: # Prevents an image URL from being stored if it is already there.\n",
    "                max_images += 1 # Accounts for a duplicate image URL by ensuring that the function still returns the number of image URLs requested.\n",
    "                break\n",
    "\n",
    "            if image.get_attribute('src') and 'http' in image.get_attribute('src'): # Checks if an image URL is usable.\n",
    "                    image_URLs.add(image.get_attribute('src')) # Stores an image URL if it is usable.\n",
    "                    print(f\"Found {len(image_URLs)}\")\n",
    "        \n",
    "    return image_URLs # Returns all of the usable image URLs.\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function that downloads the obtained images to a folder requested by the user. Here, an HTTP GET request obtains the content of each image, which are then opened as BytesIO objects. These images are later downloaded in a JPEG format to the requested folder. The function also checks that each image is actually able to be downloaded and that it is not in an invalid format or mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(download_path, urlsToBeDownloaded, file_name):\n",
    "    try:\n",
    "        image_content = requests.get(urlsToBeDownloaded).content    # Obtains the content of the image from the URL.\n",
    "        image_file = io.BytesIO(image_content)  # Creates a BytesIO object from the image.\n",
    "        image = Image.open(image_file)  # Opens the image as a BytesIO object.\n",
    "    \n",
    "        if image.mode == 'P': # Prints an error message if the image is in mode P, which prevents it from being downloaded. \n",
    "            print(f\"Skipping image with mode 'P': {urlsToBeDownloaded}\")\n",
    "            return\n",
    "\n",
    "        file_path = download_path + file_name   # The file path to the folder which the image will be stored in.\n",
    "\n",
    "        with open(file_path, \"wb\") as f:    # Saves the image to the folder in a JPEG format.\n",
    "            image.save(f, \"JPEG\")\n",
    "\n",
    "    except UnidentifiedImageError:  # Prints an error message if the image format cannot be identified.\n",
    "        print(f\"Error: Unable to identify the image format for URL: {urlsToBeDownloaded}\")\n",
    "    except Exception as e:  # Prints an error message if the image format cannot be downloaded.\n",
    "        print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the WebDriver is initialized to open Firefox. This is done by configuring FirefoxService to use GeckoDriver, which is located on my computer.\n",
    "\n",
    "Following, the WebDriver navigates to a webpage with a Google Image Search of surprised faces and executes JavaScript code that scrolls down until every image is loaded. The while loop ensures that this process is repeated and that the program does not continue until this actually happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geckodriver_path = '/Users/keigotamaki/UCLA/NSDC/Drivers/geckodriver'\n",
    "firefoxService = FIREFOXSERVICE(executable_path=geckodriver_path)\n",
    "driver = webdriver.Firefox(service = firefoxService)\n",
    "\n",
    "search_URL = \"https://www.google.com/search?client=firefox-b-d&sca_esv=f917e2823a31333e&q=human+surprised+face&tbm=isch&source=lnms&sa=X&ved=2ahUKEwjMq7WOgqiEAxWNIEQIHXkQDyQQ0pQJegQICBAB&biw=1280&bih=701&dpr=2\"\n",
    "driver.get(search_URL)\n",
    "\n",
    "last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(5)\n",
    "    new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_height == last_height:\n",
    "        break\n",
    "    last_height = new_height\n",
    "driver.execute_script(\"window.scrollTo(0, 0);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WebDriver then stores the HTML of the webpage, and BeautifulSoup parses the HTML to find elements that are candidates to be an image with a usable URL. In this case, BeautifulSoup finds all div elements with a class name of \"Q4LuWd\" and stores them into a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_html = driver.page_source\n",
    "pageSoup = bs4.BeautifulSoup(page_html, 'html.parser')\n",
    "thumbnails = driver.find_elements(By.CLASS_NAME, \"Q4LuWd\")\n",
    "time.sleep(3)\n",
    "\n",
    "len_thumbnails = len(thumbnails)\n",
    "print(\"Found %s image candidates\"%(len_thumbnails))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following, this function (implemented above) goes through each image candidate that Beautiful Soup found above and returns their image URLs if they are usable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_request = 325 # For this project, we are trying to download around 300 images but we also want to account for the number of images that cannot be downloaded.\n",
    "\n",
    "urlsToBeDownloaded = get_images(driver, thumbnails, image_request) # A function that obtains and stores the number of image URLs requested."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, another function (also implemented above) downloades the images into a chosen file. Once every image is downloaded, the driver quits and the Firefox browser is closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, urlsToBeDownloaded in enumerate(urlsToBeDownloaded):\n",
    "    download_images(\"surprised_images/\", urlsToBeDownloaded, str(i) + \".jpg\") # A function that downloades each obtained image into a requested folder.\n",
    "\n",
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
